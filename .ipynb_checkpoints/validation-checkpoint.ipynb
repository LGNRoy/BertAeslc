{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\n"
     ]
    }
   ],
   "source": [
    "%cd src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python train.py -task abs \\\n",
    "                 -mode validate \\\n",
    "                 -batch_size 3000 \\\n",
    "                 -test_batch_size 500 \\\n",
    "                 -bert_data_path ../bert_data \\\n",
    "                 -log_file ../logs/val_abs_bert_aeslc \\\n",
    "                 -model_path ../models/abs/ \\\n",
    "                 -sep_optim true \\\n",
    "                 -use_interval true \\\n",
    "                 -visible_gpus 0 \\\n",
    "                 -max_pos 512 \\\n",
    "                 -max_length 200 \\\n",
    "                 -alpha 0.95 \\\n",
    "                 -min_length 50 \\\n",
    "                 -result_path ../logs/abs_bert_aeslc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from others.logging import init_logger\n",
    "from train_abstractive import validate_abs, train_abs, baseline, test_abs, test_text_abs\n",
    "from train_extractive import train_ext, validate_ext, test_ext\n",
    "\n",
    "model_flags = ['hidden_size', 'ff_size', 'heads', 'emb_size', 'enc_layers', 'enc_hidden_size', 'enc_ff_size',\n",
    "               'dec_layers', 'dec_hidden_size', 'dec_ff_size', 'encoder', 'ff_actv', 'use_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-task\", default='ext', type=str, choices=['ext', 'abs'])\n",
    "parser.add_argument(\"-encoder\", default='bert', type=str, choices=['bert', 'baseline'])\n",
    "parser.add_argument(\"-mode\", default='train', type=str, choices=['train', 'validate', 'test'])\n",
    "parser.add_argument(\"-bert_data_path\", default='../bert_data_new/cnndm')\n",
    "parser.add_argument(\"-model_path\", default='../models/')\n",
    "parser.add_argument(\"-result_path\", default='../results/cnndm')\n",
    "parser.add_argument(\"-temp_dir\", default='../temp')\n",
    "\n",
    "parser.add_argument(\"-batch_size\", default=140, type=int)\n",
    "parser.add_argument(\"-test_batch_size\", default=200, type=int)\n",
    "\n",
    "parser.add_argument(\"-max_pos\", default=512, type=int)\n",
    "parser.add_argument(\"-use_interval\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-large\", type=bool, nargs='?',const=True,default=False)\n",
    "parser.add_argument(\"-load_from_extractive\", default='', type=str)\n",
    "\n",
    "parser.add_argument(\"-sep_optim\", type=bool, nargs='?',const=True,default=False)\n",
    "parser.add_argument(\"-lr_bert\", default=2e-3, type=float)\n",
    "parser.add_argument(\"-lr_dec\", default=2e-3, type=float)\n",
    "parser.add_argument(\"-use_bert_emb\", type=bool, nargs='?',const=True,default=False)\n",
    "\n",
    "parser.add_argument(\"-share_emb\", type=bool, nargs='?', const=True, default=False)\n",
    "parser.add_argument(\"-finetune_bert\", type=bool, nargs='?', const=True, default=True)\n",
    "parser.add_argument(\"-dec_dropout\", default=0.2, type=float)\n",
    "parser.add_argument(\"-dec_layers\", default=6, type=int)\n",
    "parser.add_argument(\"-dec_hidden_size\", default=768, type=int)\n",
    "parser.add_argument(\"-dec_heads\", default=8, type=int)\n",
    "parser.add_argument(\"-dec_ff_size\", default=2048, type=int)\n",
    "parser.add_argument(\"-enc_hidden_size\", default=512, type=int)\n",
    "parser.add_argument(\"-enc_ff_size\", default=512, type=int)\n",
    "parser.add_argument(\"-enc_dropout\", default=0.2, type=float)\n",
    "parser.add_argument(\"-enc_layers\", default=6, type=int)\n",
    "\n",
    "# params for EXT\n",
    "parser.add_argument(\"-ext_dropout\", default=0.2, type=float)\n",
    "parser.add_argument(\"-ext_layers\", default=2, type=int)\n",
    "parser.add_argument(\"-ext_hidden_size\", default=768, type=int)\n",
    "parser.add_argument(\"-ext_heads\", default=8, type=int)\n",
    "parser.add_argument(\"-ext_ff_size\", default=2048, type=int)\n",
    "\n",
    "parser.add_argument(\"-label_smoothing\", default=0.1, type=float)\n",
    "parser.add_argument(\"-generator_shard_size\", default=32, type=int)\n",
    "parser.add_argument(\"-alpha\",  default=0.6, type=float)\n",
    "parser.add_argument(\"-beam_size\", default=5, type=int)\n",
    "parser.add_argument(\"-min_length\", default=15, type=int)\n",
    "parser.add_argument(\"-max_length\", default=150, type=int)\n",
    "parser.add_argument(\"-max_tgt_len\", default=140, type=int)\n",
    "\n",
    "\n",
    "\n",
    "parser.add_argument(\"-param_init\", default=0, type=float)\n",
    "parser.add_argument(\"-param_init_glorot\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-optim\", default='adam', type=str)\n",
    "parser.add_argument(\"-lr\", default=1, type=float)\n",
    "parser.add_argument(\"-beta1\", default= 0.9, type=float)\n",
    "parser.add_argument(\"-beta2\", default=0.999, type=float)\n",
    "parser.add_argument(\"-warmup_steps\", default=8000, type=int)\n",
    "parser.add_argument(\"-warmup_steps_bert\", default=8000, type=int)\n",
    "parser.add_argument(\"-warmup_steps_dec\", default=8000, type=int)\n",
    "parser.add_argument(\"-max_grad_norm\", default=0, type=float)\n",
    "\n",
    "parser.add_argument(\"-save_checkpoint_steps\", default=5, type=int)\n",
    "parser.add_argument(\"-accum_count\", default=1, type=int)\n",
    "parser.add_argument(\"-report_every\", default=1, type=int)\n",
    "parser.add_argument(\"-train_steps\", default=1000, type=int)\n",
    "parser.add_argument(\"-recall_eval\", type=bool, nargs='?',const=True,default=False)\n",
    "\n",
    "\n",
    "parser.add_argument('-visible_gpus', default='-1', type=str)\n",
    "parser.add_argument('-gpu_ranks', default='0', type=str)\n",
    "parser.add_argument('-log_file', default='../logs/cnndm.log')\n",
    "parser.add_argument('-seed', default=666, type=int)\n",
    "\n",
    "parser.add_argument(\"-test_all\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-test_from\", default='')\n",
    "parser.add_argument(\"-test_start_from\", default=-1, type=int)\n",
    "\n",
    "parser.add_argument(\"-train_from\", default='')\n",
    "parser.add_argument(\"-report_rouge\", type=bool, nargs='?',const=True,default=True)\n",
    "parser.add_argument(\"-block_trigram\", type=bool, nargs='?', const=True, default=True)\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task = \"abs\" \n",
    "args.mode = \"validate\" \n",
    "args.batch_size = 3000 \n",
    "args.test_batch_size = 500 \n",
    "\n",
    "# args.bert_data_path = \"../bert_data/less/bert\"\n",
    "# args.log_file = \"../logs/val_abs_bert_aeslc\"\n",
    "# args.model_path = \"../models/abs/\"\n",
    "args.bert_data_path = \"../../../bertAeslc/bert_data/bert\"\n",
    "args.log_file = \"../../../val_abs_bert_aeslc\"\n",
    "args.model_path = \"../../../bertAeslc/models/abs/\"\n",
    "args.result_path = \"../../../abs_bert_aeslc\"\n",
    "\n",
    "args.sep_optim = True \n",
    "args.use_interval = True \n",
    "args.visible_gpus = \"-1\" \n",
    "args.max_pos = 512 \n",
    "args.max_length = 200 \n",
    "args.alpha = 0.95 \n",
    "args.min_length = 50 \n",
    "# args.result_path = \"../logs/abs_bert_aeslc\"\n",
    "\n",
    "\n",
    "args.gpu_ranks = [int(i) for i in range(len(args.visible_gpus.split(',')))]\n",
    "args.world_size = len(args.gpu_ranks)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.visible_gpus\n",
    "\n",
    "init_logger(args.log_file)\n",
    "device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
    "device_id = 0 if device == \"cuda\" else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-09 15:11:21,696 INFO] Loading test dataset from ../../../bertAeslc/bert_data/bert.test.pt, number of examples: 1906\n"
     ]
    }
   ],
   "source": [
    "from models import data_loader, model_builder\n",
    "from models.data_loader import load_dataset\n",
    "test_iter = data_loader.Dataloader(args, load_dataset(args, 'test', shuffle=False),\n",
    "                                   args.test_batch_size, device,\n",
    "                                   shuffle=False, is_test=True)\n",
    "data_iter = test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-09 15:11:30,049 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, cache_dir=args.temp_dir)\n",
    "symbols = {'BOS': tokenizer.vocab['[unused0]'], 'EOS': tokenizer.vocab['[unused1]'],\n",
    "           'PAD': tokenizer.vocab['[PAD]'], 'EOQ': tokenizer.vocab['[unused2]']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-09 15:12:13,366 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp\\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-10-09 15:12:13,367 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-10-09 15:12:14,404 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp\\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AbsSummarizer(\n",
       "  (bert): Bert(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (pos_emb): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2)\n",
       "    )\n",
       "    (transformer_layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (context_attn): MultiHeadedAttention(\n",
       "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (softmax): Softmax()\n",
       "          (dropout): Dropout(p=0.2)\n",
       "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "          (dropout_1): Dropout(p=0.2)\n",
       "          (dropout_2): Dropout(p=0.2)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "        (drop): Dropout(p=0.2)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (generator): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    (1): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models.model_builder import AbsSummarizer\n",
    "test_from = \"../../../bertAeslc/models/abs/model_step_4000.pt\"\n",
    "# test_from = \"../models/abs/model_step_2000.pt\"\n",
    "\n",
    "checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\n",
    "model = AbsSummarizer(args, device, checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from others.logging import logger, init_logger\n",
    "init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.predictor import Translator, build_predictor\n",
    "translator = build_predictor(args, tokenizer, symbols, model, logger)\n",
    "# translator.translate(data_iter, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_iter:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = translator.translate_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(line):\n",
    "    print([translator.vocab.ids_to_tokens[int(n)] for n in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'n', 't', 'a', 't', 'i', 'o', 'n', '[unused2]', 'f', 'o', 'r', '[unused2]', 'y', 'o', 'u', '[unused2]', 'm', 'e', 'e', 't', 'i', 'n', 'g', '[unused2]', 'm', 'a', 't', '[unused2]', '?', '?', '?', '!', '~', 'a', 't', 'a', 'l', 'a', 't', 'o', '[unused2]', 'f', '[unused2]', '[unused2]', '-', '[unused2]', 't', 'e', 's', '[unused1]']\n"
     ]
    }
   ],
   "source": [
    "decode(batch_data['predictions'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1045, 1050, 1056, 1037, 1056, 1045, 1051, 1050,    3, 1042, 1051, 1054,\n",
       "           3, 1061, 1051, 1057,    3, 1049, 1041, 1041, 1056, 1045, 1050, 1043,\n",
       "           3, 1049, 1037, 1056,    3, 1029, 1029, 1029,  999, 1066, 1037, 1056,\n",
       "        1037, 1048, 1037, 1056, 1051,    3, 1042,    3,    3, 1011,    3, 1056,\n",
       "        1041, 1055,    2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = translator.from_batch(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch_data[\"batch\"]\n",
    "batch_size = batch.batch_size\n",
    "preds, pred_score, gold_score, tgt_str, src = batch_data[\"predictions\"],batch_data[\"scores\"],batch_data[\"gold_score\"],batch.tgt_str, batch.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sents = [translator.vocab.ids_to_tokens[int(n)] for n in preds[b][0]]\n",
    "pred_sents = ' '.join(pred_sents).replace(' ##','')\n",
    "gold_sent = ' '.join(tgt_str[b].split())\n",
    "raw_src = [translator.vocab.ids_to_tokens[int(t)] for t in src[b]][:500]\n",
    "raw_src = ' '.join(raw_src)\n",
    "translation = (pred_sents, gold_sent, raw_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trans in translations:\n",
    "    pred, gold, src = trans\n",
    "    pred_str = pred.replace('[unused0]', '').replace('[unused3]', '').replace('[PAD]', '').replace('[unused1]', '').replace(r' +', ' ').replace(' [unused2] ', '<q>').replace('[unused2]', '').strip()\n",
    "    gold_str = gold.strip()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(line):\n",
    "    print([translator.vocab.ids_to_tokens[int(n)] for n in line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'please', 'give', 'my', 'e', '##ol', 'id', 'the', 'ability', 'to', 'trade', 'canadian', 'gas', 'products', '.', '[SEP]', '[CLS]', 'my', 'id', 'is', 'ad', '##m', '81', '##30', '##0', '.', '[SEP]', '[CLS]', 'call', 'me', 'at', '3', '##-', '##47', '##43', 'if', 'you', 'have', 'any', 'questions', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "decode(batch.src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-07 21:12:47,699 INFO] Loading test dataset from ../bert_data/bert.test.pt, number of examples: 1906\n"
     ]
    }
   ],
   "source": [
    "for data in load_dataset(args, 'test', shuffle=False):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[unused0]', 'h', 'u', 'n', 't', 'l', 'e', 'y', '[unused2]', '/', '[unused2]', 'q', 'u', 'e', 's', 't', 'i', 'o', 'n', '[unused1]']\n"
     ]
    }
   ],
   "source": [
    "decode(data[0]['tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.load(\"../bert_data/less/dev_bert.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[unused0]', 'confirmation', ':', 'risk', 'management', 'simulation', 'meeting', '10', '/', '30', '/', '01', '[unused1]']\n"
     ]
    }
   ],
   "source": [
    "decode(dev[0]['tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-09 15:31:32,871 INFO] Loading checkpoint from ../../../bertAeslc/models/abs/model_step_4000.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='../../../bertAeslc/bert_data/bert', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../../../val_abs_bert_aeslc', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='validate', model_path='../../../bertAeslc/models/abs/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../../../abs_bert_aeslc', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=True, test_batch_size=500, test_from='', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-09 15:31:52,408 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp\\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-10-09 15:31:52,412 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-10-09 15:31:53,432 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp\\aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-10-09 15:32:08,915 INFO] Loading test dataset from ../../../bertAeslc/bert_data/bert.test.pt, number of examples: 1906\n",
      "[2019-10-09 15:32:09,840 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-10-09 17:27:09,281 INFO] Calculating Rouge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906\n",
      "1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-09 17:27:11,472 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2019-10-09 17:27:11,472 INFO] Writing summaries.\n",
      "2019-10-09 17:27:11,480 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp\\tmpdkscplpb\\system and model files to ../temp\\tmpdkscplpb\\model.\n",
      "[2019-10-09 17:27:11,480 INFO] Processing summaries. Saving system files to ../temp\\tmpdkscplpb\\system and model files to ../temp\\tmpdkscplpb\\model.\n",
      "2019-10-09 17:27:11,486 [MainThread  ] [INFO ]  Processing files in ../temp\\rouge-tmp-2019-10-09-17-27-09/candidate/.\n",
      "[2019-10-09 17:27:11,486 INFO] Processing files in ../temp\\rouge-tmp-2019-10-09-17-27-09/candidate/.\n",
      "2019-10-09 17:27:12,220 [MainThread  ] [INFO ]  Saved processed files to ../temp\\tmpdkscplpb\\system.\n",
      "[2019-10-09 17:27:12,220 INFO] Saved processed files to ../temp\\tmpdkscplpb\\system.\n",
      "2019-10-09 17:27:12,222 [MainThread  ] [INFO ]  Processing files in ../temp\\rouge-tmp-2019-10-09-17-27-09/reference/.\n",
      "[2019-10-09 17:27:12,222 INFO] Processing files in ../temp\\rouge-tmp-2019-10-09-17-27-09/reference/.\n",
      "2019-10-09 17:27:13,079 [MainThread  ] [INFO ]  Saved processed files to ../temp\\tmpdkscplpb\\model.\n",
      "[2019-10-09 17:27:13,079 INFO] Saved processed files to ../temp\\tmpdkscplpb\\model.\n",
      "2019-10-09 17:27:13,094 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp\\tmplj2_7lo3\\rouge_conf.xml\n",
      "[2019-10-09 17:27:13,094 INFO] Written ROUGE configuration to ../temp\\tmplj2_7lo3\\rouge_conf.xml\n",
      "2019-10-09 17:27:13,095 [MainThread  ] [INFO ]  Running ROUGE with command D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\ROUGE-1.5.5.pl -e D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\data -c 95 -m -r 1000 -n 2 -a ../temp\\tmplj2_7lo3\\rouge_conf.xml\n",
      "[2019-10-09 17:27:13,095 INFO] Running ROUGE with command D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\ROUGE-1.5.5.pl -e D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\data -c 95 -m -r 1000 -n 2 -a ../temp\\tmplj2_7lo3\\rouge_conf.xml\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1  Win32 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d991fd0bac8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"../../../bertAeslc/models/abs/model_step_4000.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_abs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\\train_abstractive.py\u001b[0m in \u001b[0;36mtest_abs\u001b[1;34m(args, device_id, pt, step)\u001b[0m\n\u001b[0;32m    231\u001b[0m                'PAD': tokenizer.vocab['[PAD]'], 'EOQ': tokenizer.vocab['[unused2]']}\n\u001b[0;32m    232\u001b[0m     \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m     \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\\models\\predictor.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, data_iter, step, attn_debug)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[0mrouges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_report_rouge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Rouges at step %d \\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrouge_results_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrouges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard_writer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\\models\\predictor.py\u001b[0m in \u001b[0;36m_report_rouge\u001b[1;34m(self, gold_path, can_path)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_report_rouge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgold_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating Rouge\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mresults_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_rouge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgold_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\\others\\utils.py\u001b[0m in \u001b[0;36mtest_rouge\u001b[1;34m(temp_dir, cand, ref)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_filename_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ref.#ID#.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem_filename_pattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'cand.(\\d+).txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mrouge_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrouge_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mresults_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrouge_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\\others\\pyrouge.py\u001b[0m in \u001b[0;36mconvert_and_evaluate\u001b[1;34m(self, system_id, split_sentences, rouge_args)\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__write_summaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m         \u001b[0mrouge_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msystem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrouge_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrouge_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\Capstone\\BertAeslc-master\\BertAeslc\\src\\others\\pyrouge.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, system_id, rouge_args)\u001b[0m\n\u001b[0;32m    371\u001b[0m         self.log.info(\n\u001b[0;32m    372\u001b[0m             \"Running ROUGE with command {}\".format(\" \".join(command)))\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[0mrouge_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"UTF-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrouge_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[1;32m--> 395\u001b[1;33m                **kwargs).stdout\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stderr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    473\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    773\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1179\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1  Win32 "
     ]
    }
   ],
   "source": [
    "cp = \"../../../bertAeslc/models/abs/model_step_4000.pt\"\n",
    "step = int(cp.split('.')[-2].split('_')[-1])\n",
    "test_abs(args, device_id, cp, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tcost 0.0080 seconds\ttotal 0.0080 seconds\n",
      "19\tcost 0.0060 seconds\ttotal 0.0140 seconds\n",
      "29\tcost 0.0070 seconds\ttotal 0.0209 seconds\n",
      "39\tcost 0.0070 seconds\ttotal 0.0279 seconds\n",
      "49\tcost 0.0090 seconds\ttotal 0.0369 seconds\n",
      "59\tcost 0.0060 seconds\ttotal 0.0429 seconds\n",
      "69\tcost 0.0080 seconds\ttotal 0.0509 seconds\n",
      "79\tcost 0.0060 seconds\ttotal 0.0568 seconds\n",
      "89\tcost 0.0060 seconds\ttotal 0.0628 seconds\n",
      "99\tcost 0.0060 seconds\ttotal 0.0688 seconds\n",
      "109\tcost 0.0070 seconds\ttotal 0.0758 seconds\n",
      "119\tcost 0.0090 seconds\ttotal 0.0848 seconds\n",
      "129\tcost 0.0070 seconds\ttotal 0.0918 seconds\n",
      "139\tcost 0.0060 seconds\ttotal 0.0977 seconds\n",
      "149\tcost 0.0070 seconds\ttotal 0.1047 seconds\n",
      "159\tcost 0.0070 seconds\ttotal 0.1117 seconds\n",
      "169\tcost 0.0070 seconds\ttotal 0.1187 seconds\n",
      "------------------------------------------------------------------\n",
      "Spilit file finished, totally cost 0.1247 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def splitFiles(file, out_head):\n",
    "    start = time.time()\n",
    "    timestemp = time.time()\n",
    "    index = 0\n",
    "    for line in open(file, errors='ignore'):\n",
    "        line = line.replace(\"<unk>\", \"\")\n",
    "        conntent = line.replace(\" </t> <t> \", \"\\n\").replace(\" </t>\", \"\").replace(\"<t> \",\"\")\n",
    "        out_file_name = \"{}.{}.txt\".format(out_head, index)\n",
    "        writer = open(out_file_name, 'w')\n",
    "        writer.writelines(conntent)\n",
    "        writer.close()\n",
    "        if index%10 == 9:\n",
    "            now = time.time()\n",
    "            print(\"{}\\tcost {:.4f} seconds\\ttotal {:.4f} seconds\".format(index, now-timestemp, now-start))\n",
    "            timestemp = now\n",
    "        index += 1\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"Spilit file finished, totally cost {:.4f} seconds\".format(time.time()-start))\n",
    "\n",
    "file = \"../logs/right1/gold/abs_bert_aeslc.4000.gold\"\n",
    "head = \"../logs/right1/gold/text\"\n",
    "splitFiles(file, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-08 12:57:44,756 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2019-10-08 12:57:44,756 INFO] Writing summaries.\n",
      "2019-10-08 12:57:44,760 [MainThread  ] [INFO ]  Processing summaries. Saving system files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\system and model files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\model.\n",
      "[2019-10-08 12:57:44,760 INFO] Processing summaries. Saving system files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\system and model files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\model.\n",
      "2019-10-08 12:57:44,762 [MainThread  ] [INFO ]  Processing files in ../logs/right1/gold.\n",
      "[2019-10-08 12:57:44,762 INFO] Processing files in ../logs/right1/gold.\n",
      "2019-10-08 12:57:44,764 [MainThread  ] [INFO ]  Processing abs_bert_aeslc.4000.gold.\n",
      "[2019-10-08 12:57:44,764 INFO] Processing abs_bert_aeslc.4000.gold.\n",
      "2019-10-08 12:57:44,767 [MainThread  ] [INFO ]  Processing text.0.txt.\n",
      "[2019-10-08 12:57:44,767 INFO] Processing text.0.txt.\n",
      "2019-10-08 12:57:44,770 [MainThread  ] [INFO ]  Processing text.1.txt.\n",
      "[2019-10-08 12:57:44,770 INFO] Processing text.1.txt.\n",
      "2019-10-08 12:57:44,773 [MainThread  ] [INFO ]  Processing text.10.txt.\n",
      "[2019-10-08 12:57:44,773 INFO] Processing text.10.txt.\n",
      "2019-10-08 12:57:44,777 [MainThread  ] [INFO ]  Processing text.100.txt.\n",
      "[2019-10-08 12:57:44,777 INFO] Processing text.100.txt.\n",
      "2019-10-08 12:57:44,780 [MainThread  ] [INFO ]  Processing text.101.txt.\n",
      "[2019-10-08 12:57:44,780 INFO] Processing text.101.txt.\n",
      "2019-10-08 12:57:44,782 [MainThread  ] [INFO ]  Processing text.102.txt.\n",
      "[2019-10-08 12:57:44,782 INFO] Processing text.102.txt.\n",
      "2019-10-08 12:57:44,784 [MainThread  ] [INFO ]  Processing text.103.txt.\n",
      "[2019-10-08 12:57:44,784 INFO] Processing text.103.txt.\n",
      "2019-10-08 12:57:44,787 [MainThread  ] [INFO ]  Processing text.104.txt.\n",
      "[2019-10-08 12:57:44,787 INFO] Processing text.104.txt.\n",
      "2019-10-08 12:57:44,790 [MainThread  ] [INFO ]  Processing text.105.txt.\n",
      "[2019-10-08 12:57:44,790 INFO] Processing text.105.txt.\n",
      "2019-10-08 12:57:44,793 [MainThread  ] [INFO ]  Processing text.106.txt.\n",
      "[2019-10-08 12:57:44,793 INFO] Processing text.106.txt.\n",
      "2019-10-08 12:57:44,795 [MainThread  ] [INFO ]  Processing text.107.txt.\n",
      "[2019-10-08 12:57:44,795 INFO] Processing text.107.txt.\n",
      "2019-10-08 12:57:44,798 [MainThread  ] [INFO ]  Processing text.108.txt.\n",
      "[2019-10-08 12:57:44,798 INFO] Processing text.108.txt.\n",
      "2019-10-08 12:57:44,801 [MainThread  ] [INFO ]  Processing text.109.txt.\n",
      "[2019-10-08 12:57:44,801 INFO] Processing text.109.txt.\n",
      "2019-10-08 12:57:44,804 [MainThread  ] [INFO ]  Processing text.11.txt.\n",
      "[2019-10-08 12:57:44,804 INFO] Processing text.11.txt.\n",
      "2019-10-08 12:57:44,806 [MainThread  ] [INFO ]  Processing text.110.txt.\n",
      "[2019-10-08 12:57:44,806 INFO] Processing text.110.txt.\n",
      "2019-10-08 12:57:44,808 [MainThread  ] [INFO ]  Processing text.111.txt.\n",
      "[2019-10-08 12:57:44,808 INFO] Processing text.111.txt.\n",
      "2019-10-08 12:57:44,810 [MainThread  ] [INFO ]  Processing text.112.txt.\n",
      "[2019-10-08 12:57:44,810 INFO] Processing text.112.txt.\n",
      "2019-10-08 12:57:44,813 [MainThread  ] [INFO ]  Processing text.113.txt.\n",
      "[2019-10-08 12:57:44,813 INFO] Processing text.113.txt.\n",
      "2019-10-08 12:57:44,815 [MainThread  ] [INFO ]  Processing text.114.txt.\n",
      "[2019-10-08 12:57:44,815 INFO] Processing text.114.txt.\n",
      "2019-10-08 12:57:44,818 [MainThread  ] [INFO ]  Processing text.115.txt.\n",
      "[2019-10-08 12:57:44,818 INFO] Processing text.115.txt.\n",
      "2019-10-08 12:57:44,821 [MainThread  ] [INFO ]  Processing text.116.txt.\n",
      "[2019-10-08 12:57:44,821 INFO] Processing text.116.txt.\n",
      "2019-10-08 12:57:44,824 [MainThread  ] [INFO ]  Processing text.117.txt.\n",
      "[2019-10-08 12:57:44,824 INFO] Processing text.117.txt.\n",
      "2019-10-08 12:57:44,826 [MainThread  ] [INFO ]  Processing text.118.txt.\n",
      "[2019-10-08 12:57:44,826 INFO] Processing text.118.txt.\n",
      "2019-10-08 12:57:44,829 [MainThread  ] [INFO ]  Processing text.119.txt.\n",
      "[2019-10-08 12:57:44,829 INFO] Processing text.119.txt.\n",
      "2019-10-08 12:57:44,832 [MainThread  ] [INFO ]  Processing text.12.txt.\n",
      "[2019-10-08 12:57:44,832 INFO] Processing text.12.txt.\n",
      "2019-10-08 12:57:44,835 [MainThread  ] [INFO ]  Processing text.120.txt.\n",
      "[2019-10-08 12:57:44,835 INFO] Processing text.120.txt.\n",
      "2019-10-08 12:57:44,838 [MainThread  ] [INFO ]  Processing text.121.txt.\n",
      "[2019-10-08 12:57:44,838 INFO] Processing text.121.txt.\n",
      "2019-10-08 12:57:44,840 [MainThread  ] [INFO ]  Processing text.122.txt.\n",
      "[2019-10-08 12:57:44,840 INFO] Processing text.122.txt.\n",
      "2019-10-08 12:57:44,843 [MainThread  ] [INFO ]  Processing text.123.txt.\n",
      "[2019-10-08 12:57:44,843 INFO] Processing text.123.txt.\n",
      "2019-10-08 12:57:44,845 [MainThread  ] [INFO ]  Processing text.124.txt.\n",
      "[2019-10-08 12:57:44,845 INFO] Processing text.124.txt.\n",
      "2019-10-08 12:57:44,848 [MainThread  ] [INFO ]  Processing text.125.txt.\n",
      "[2019-10-08 12:57:44,848 INFO] Processing text.125.txt.\n",
      "2019-10-08 12:57:44,850 [MainThread  ] [INFO ]  Processing text.126.txt.\n",
      "[2019-10-08 12:57:44,850 INFO] Processing text.126.txt.\n",
      "2019-10-08 12:57:44,854 [MainThread  ] [INFO ]  Processing text.127.txt.\n",
      "[2019-10-08 12:57:44,854 INFO] Processing text.127.txt.\n",
      "2019-10-08 12:57:44,856 [MainThread  ] [INFO ]  Processing text.128.txt.\n",
      "[2019-10-08 12:57:44,856 INFO] Processing text.128.txt.\n",
      "2019-10-08 12:57:44,858 [MainThread  ] [INFO ]  Processing text.129.txt.\n",
      "[2019-10-08 12:57:44,858 INFO] Processing text.129.txt.\n",
      "2019-10-08 12:57:44,860 [MainThread  ] [INFO ]  Processing text.13.txt.\n",
      "[2019-10-08 12:57:44,860 INFO] Processing text.13.txt.\n",
      "2019-10-08 12:57:44,863 [MainThread  ] [INFO ]  Processing text.130.txt.\n",
      "[2019-10-08 12:57:44,863 INFO] Processing text.130.txt.\n",
      "2019-10-08 12:57:44,865 [MainThread  ] [INFO ]  Processing text.131.txt.\n",
      "[2019-10-08 12:57:44,865 INFO] Processing text.131.txt.\n",
      "2019-10-08 12:57:44,868 [MainThread  ] [INFO ]  Processing text.132.txt.\n",
      "[2019-10-08 12:57:44,868 INFO] Processing text.132.txt.\n",
      "2019-10-08 12:57:44,870 [MainThread  ] [INFO ]  Processing text.133.txt.\n",
      "[2019-10-08 12:57:44,870 INFO] Processing text.133.txt.\n",
      "2019-10-08 12:57:44,873 [MainThread  ] [INFO ]  Processing text.134.txt.\n",
      "[2019-10-08 12:57:44,873 INFO] Processing text.134.txt.\n",
      "2019-10-08 12:57:44,875 [MainThread  ] [INFO ]  Processing text.135.txt.\n",
      "[2019-10-08 12:57:44,875 INFO] Processing text.135.txt.\n",
      "2019-10-08 12:57:44,877 [MainThread  ] [INFO ]  Processing text.136.txt.\n",
      "[2019-10-08 12:57:44,877 INFO] Processing text.136.txt.\n",
      "2019-10-08 12:57:44,879 [MainThread  ] [INFO ]  Processing text.137.txt.\n",
      "[2019-10-08 12:57:44,879 INFO] Processing text.137.txt.\n",
      "2019-10-08 12:57:44,882 [MainThread  ] [INFO ]  Processing text.138.txt.\n",
      "[2019-10-08 12:57:44,882 INFO] Processing text.138.txt.\n",
      "2019-10-08 12:57:44,884 [MainThread  ] [INFO ]  Processing text.139.txt.\n",
      "[2019-10-08 12:57:44,884 INFO] Processing text.139.txt.\n",
      "2019-10-08 12:57:44,888 [MainThread  ] [INFO ]  Processing text.14.txt.\n",
      "[2019-10-08 12:57:44,888 INFO] Processing text.14.txt.\n",
      "2019-10-08 12:57:44,890 [MainThread  ] [INFO ]  Processing text.140.txt.\n",
      "[2019-10-08 12:57:44,890 INFO] Processing text.140.txt.\n",
      "2019-10-08 12:57:44,892 [MainThread  ] [INFO ]  Processing text.141.txt.\n",
      "[2019-10-08 12:57:44,892 INFO] Processing text.141.txt.\n",
      "2019-10-08 12:57:44,896 [MainThread  ] [INFO ]  Processing text.142.txt.\n",
      "[2019-10-08 12:57:44,896 INFO] Processing text.142.txt.\n",
      "2019-10-08 12:57:44,898 [MainThread  ] [INFO ]  Processing text.143.txt.\n",
      "[2019-10-08 12:57:44,898 INFO] Processing text.143.txt.\n",
      "2019-10-08 12:57:44,900 [MainThread  ] [INFO ]  Processing text.144.txt.\n",
      "[2019-10-08 12:57:44,900 INFO] Processing text.144.txt.\n",
      "2019-10-08 12:57:44,903 [MainThread  ] [INFO ]  Processing text.145.txt.\n",
      "[2019-10-08 12:57:44,903 INFO] Processing text.145.txt.\n",
      "2019-10-08 12:57:44,905 [MainThread  ] [INFO ]  Processing text.146.txt.\n",
      "[2019-10-08 12:57:44,905 INFO] Processing text.146.txt.\n",
      "2019-10-08 12:57:44,907 [MainThread  ] [INFO ]  Processing text.147.txt.\n",
      "[2019-10-08 12:57:44,907 INFO] Processing text.147.txt.\n",
      "2019-10-08 12:57:44,909 [MainThread  ] [INFO ]  Processing text.148.txt.\n",
      "[2019-10-08 12:57:44,909 INFO] Processing text.148.txt.\n",
      "2019-10-08 12:57:44,912 [MainThread  ] [INFO ]  Processing text.149.txt.\n",
      "[2019-10-08 12:57:44,912 INFO] Processing text.149.txt.\n",
      "2019-10-08 12:57:44,914 [MainThread  ] [INFO ]  Processing text.15.txt.\n",
      "[2019-10-08 12:57:44,914 INFO] Processing text.15.txt.\n",
      "2019-10-08 12:57:44,917 [MainThread  ] [INFO ]  Processing text.150.txt.\n",
      "[2019-10-08 12:57:44,917 INFO] Processing text.150.txt.\n",
      "2019-10-08 12:57:44,920 [MainThread  ] [INFO ]  Processing text.151.txt.\n",
      "[2019-10-08 12:57:44,920 INFO] Processing text.151.txt.\n",
      "2019-10-08 12:57:44,922 [MainThread  ] [INFO ]  Processing text.152.txt.\n",
      "[2019-10-08 12:57:44,922 INFO] Processing text.152.txt.\n",
      "2019-10-08 12:57:44,925 [MainThread  ] [INFO ]  Processing text.153.txt.\n",
      "[2019-10-08 12:57:44,925 INFO] Processing text.153.txt.\n",
      "2019-10-08 12:57:44,928 [MainThread  ] [INFO ]  Processing text.154.txt.\n",
      "[2019-10-08 12:57:44,928 INFO] Processing text.154.txt.\n",
      "2019-10-08 12:57:44,930 [MainThread  ] [INFO ]  Processing text.155.txt.\n",
      "[2019-10-08 12:57:44,930 INFO] Processing text.155.txt.\n",
      "2019-10-08 12:57:44,933 [MainThread  ] [INFO ]  Processing text.156.txt.\n",
      "[2019-10-08 12:57:44,933 INFO] Processing text.156.txt.\n",
      "2019-10-08 12:57:44,936 [MainThread  ] [INFO ]  Processing text.157.txt.\n",
      "[2019-10-08 12:57:44,936 INFO] Processing text.157.txt.\n",
      "2019-10-08 12:57:44,939 [MainThread  ] [INFO ]  Processing text.158.txt.\n",
      "[2019-10-08 12:57:44,939 INFO] Processing text.158.txt.\n",
      "2019-10-08 12:57:44,941 [MainThread  ] [INFO ]  Processing text.159.txt.\n",
      "[2019-10-08 12:57:44,941 INFO] Processing text.159.txt.\n",
      "2019-10-08 12:57:44,944 [MainThread  ] [INFO ]  Processing text.16.txt.\n",
      "[2019-10-08 12:57:44,944 INFO] Processing text.16.txt.\n",
      "2019-10-08 12:57:44,947 [MainThread  ] [INFO ]  Processing text.160.txt.\n",
      "[2019-10-08 12:57:44,947 INFO] Processing text.160.txt.\n",
      "2019-10-08 12:57:44,949 [MainThread  ] [INFO ]  Processing text.161.txt.\n",
      "[2019-10-08 12:57:44,949 INFO] Processing text.161.txt.\n",
      "2019-10-08 12:57:44,951 [MainThread  ] [INFO ]  Processing text.162.txt.\n",
      "[2019-10-08 12:57:44,951 INFO] Processing text.162.txt.\n",
      "2019-10-08 12:57:44,954 [MainThread  ] [INFO ]  Processing text.163.txt.\n",
      "[2019-10-08 12:57:44,954 INFO] Processing text.163.txt.\n",
      "2019-10-08 12:57:44,957 [MainThread  ] [INFO ]  Processing text.164.txt.\n",
      "[2019-10-08 12:57:44,957 INFO] Processing text.164.txt.\n",
      "2019-10-08 12:57:44,959 [MainThread  ] [INFO ]  Processing text.165.txt.\n",
      "[2019-10-08 12:57:44,959 INFO] Processing text.165.txt.\n",
      "2019-10-08 12:57:44,961 [MainThread  ] [INFO ]  Processing text.166.txt.\n",
      "[2019-10-08 12:57:44,961 INFO] Processing text.166.txt.\n",
      "2019-10-08 12:57:44,964 [MainThread  ] [INFO ]  Processing text.167.txt.\n",
      "[2019-10-08 12:57:44,964 INFO] Processing text.167.txt.\n",
      "2019-10-08 12:57:44,966 [MainThread  ] [INFO ]  Processing text.168.txt.\n",
      "[2019-10-08 12:57:44,966 INFO] Processing text.168.txt.\n",
      "2019-10-08 12:57:44,969 [MainThread  ] [INFO ]  Processing text.169.txt.\n",
      "[2019-10-08 12:57:44,969 INFO] Processing text.169.txt.\n",
      "2019-10-08 12:57:44,972 [MainThread  ] [INFO ]  Processing text.17.txt.\n",
      "[2019-10-08 12:57:44,972 INFO] Processing text.17.txt.\n",
      "2019-10-08 12:57:44,974 [MainThread  ] [INFO ]  Processing text.170.txt.\n",
      "[2019-10-08 12:57:44,974 INFO] Processing text.170.txt.\n",
      "2019-10-08 12:57:44,977 [MainThread  ] [INFO ]  Processing text.171.txt.\n",
      "[2019-10-08 12:57:44,977 INFO] Processing text.171.txt.\n",
      "2019-10-08 12:57:44,980 [MainThread  ] [INFO ]  Processing text.172.txt.\n",
      "[2019-10-08 12:57:44,980 INFO] Processing text.172.txt.\n",
      "2019-10-08 12:57:44,982 [MainThread  ] [INFO ]  Processing text.173.txt.\n",
      "[2019-10-08 12:57:44,982 INFO] Processing text.173.txt.\n",
      "2019-10-08 12:57:44,984 [MainThread  ] [INFO ]  Processing text.18.txt.\n",
      "[2019-10-08 12:57:44,984 INFO] Processing text.18.txt.\n",
      "2019-10-08 12:57:44,987 [MainThread  ] [INFO ]  Processing text.19.txt.\n",
      "[2019-10-08 12:57:44,987 INFO] Processing text.19.txt.\n",
      "2019-10-08 12:57:44,989 [MainThread  ] [INFO ]  Processing text.2.txt.\n",
      "[2019-10-08 12:57:44,989 INFO] Processing text.2.txt.\n",
      "2019-10-08 12:57:44,992 [MainThread  ] [INFO ]  Processing text.20.txt.\n",
      "[2019-10-08 12:57:44,992 INFO] Processing text.20.txt.\n",
      "2019-10-08 12:57:44,994 [MainThread  ] [INFO ]  Processing text.21.txt.\n",
      "[2019-10-08 12:57:44,994 INFO] Processing text.21.txt.\n",
      "2019-10-08 12:57:44,997 [MainThread  ] [INFO ]  Processing text.22.txt.\n",
      "[2019-10-08 12:57:44,997 INFO] Processing text.22.txt.\n",
      "2019-10-08 12:57:44,999 [MainThread  ] [INFO ]  Processing text.23.txt.\n",
      "[2019-10-08 12:57:44,999 INFO] Processing text.23.txt.\n",
      "2019-10-08 12:57:45,001 [MainThread  ] [INFO ]  Processing text.24.txt.\n",
      "[2019-10-08 12:57:45,001 INFO] Processing text.24.txt.\n",
      "2019-10-08 12:57:45,004 [MainThread  ] [INFO ]  Processing text.25.txt.\n",
      "[2019-10-08 12:57:45,004 INFO] Processing text.25.txt.\n",
      "2019-10-08 12:57:45,006 [MainThread  ] [INFO ]  Processing text.26.txt.\n",
      "[2019-10-08 12:57:45,006 INFO] Processing text.26.txt.\n",
      "2019-10-08 12:57:45,009 [MainThread  ] [INFO ]  Processing text.27.txt.\n",
      "[2019-10-08 12:57:45,009 INFO] Processing text.27.txt.\n",
      "2019-10-08 12:57:45,012 [MainThread  ] [INFO ]  Processing text.28.txt.\n",
      "[2019-10-08 12:57:45,012 INFO] Processing text.28.txt.\n",
      "2019-10-08 12:57:45,014 [MainThread  ] [INFO ]  Processing text.29.txt.\n",
      "[2019-10-08 12:57:45,014 INFO] Processing text.29.txt.\n",
      "2019-10-08 12:57:45,017 [MainThread  ] [INFO ]  Processing text.3.txt.\n",
      "[2019-10-08 12:57:45,017 INFO] Processing text.3.txt.\n",
      "2019-10-08 12:57:45,019 [MainThread  ] [INFO ]  Processing text.30.txt.\n",
      "[2019-10-08 12:57:45,019 INFO] Processing text.30.txt.\n",
      "2019-10-08 12:57:45,022 [MainThread  ] [INFO ]  Processing text.31.txt.\n",
      "[2019-10-08 12:57:45,022 INFO] Processing text.31.txt.\n",
      "2019-10-08 12:57:45,025 [MainThread  ] [INFO ]  Processing text.32.txt.\n",
      "[2019-10-08 12:57:45,025 INFO] Processing text.32.txt.\n",
      "2019-10-08 12:57:45,027 [MainThread  ] [INFO ]  Processing text.33.txt.\n",
      "[2019-10-08 12:57:45,027 INFO] Processing text.33.txt.\n",
      "2019-10-08 12:57:45,030 [MainThread  ] [INFO ]  Processing text.34.txt.\n",
      "[2019-10-08 12:57:45,030 INFO] Processing text.34.txt.\n",
      "2019-10-08 12:57:45,032 [MainThread  ] [INFO ]  Processing text.35.txt.\n",
      "[2019-10-08 12:57:45,032 INFO] Processing text.35.txt.\n",
      "2019-10-08 12:57:45,034 [MainThread  ] [INFO ]  Processing text.36.txt.\n",
      "[2019-10-08 12:57:45,034 INFO] Processing text.36.txt.\n",
      "2019-10-08 12:57:45,037 [MainThread  ] [INFO ]  Processing text.37.txt.\n",
      "[2019-10-08 12:57:45,037 INFO] Processing text.37.txt.\n",
      "2019-10-08 12:57:45,039 [MainThread  ] [INFO ]  Processing text.38.txt.\n",
      "[2019-10-08 12:57:45,039 INFO] Processing text.38.txt.\n",
      "2019-10-08 12:57:45,043 [MainThread  ] [INFO ]  Processing text.39.txt.\n",
      "[2019-10-08 12:57:45,043 INFO] Processing text.39.txt.\n",
      "2019-10-08 12:57:45,046 [MainThread  ] [INFO ]  Processing text.4.txt.\n",
      "[2019-10-08 12:57:45,046 INFO] Processing text.4.txt.\n",
      "2019-10-08 12:57:45,048 [MainThread  ] [INFO ]  Processing text.40.txt.\n",
      "[2019-10-08 12:57:45,048 INFO] Processing text.40.txt.\n",
      "2019-10-08 12:57:45,050 [MainThread  ] [INFO ]  Processing text.41.txt.\n",
      "[2019-10-08 12:57:45,050 INFO] Processing text.41.txt.\n",
      "2019-10-08 12:57:45,053 [MainThread  ] [INFO ]  Processing text.42.txt.\n",
      "[2019-10-08 12:57:45,053 INFO] Processing text.42.txt.\n",
      "2019-10-08 12:57:45,055 [MainThread  ] [INFO ]  Processing text.43.txt.\n",
      "[2019-10-08 12:57:45,055 INFO] Processing text.43.txt.\n",
      "2019-10-08 12:57:45,057 [MainThread  ] [INFO ]  Processing text.44.txt.\n",
      "[2019-10-08 12:57:45,057 INFO] Processing text.44.txt.\n",
      "2019-10-08 12:57:45,061 [MainThread  ] [INFO ]  Processing text.45.txt.\n",
      "[2019-10-08 12:57:45,061 INFO] Processing text.45.txt.\n",
      "2019-10-08 12:57:45,063 [MainThread  ] [INFO ]  Processing text.46.txt.\n",
      "[2019-10-08 12:57:45,063 INFO] Processing text.46.txt.\n",
      "2019-10-08 12:57:45,065 [MainThread  ] [INFO ]  Processing text.47.txt.\n",
      "[2019-10-08 12:57:45,065 INFO] Processing text.47.txt.\n",
      "2019-10-08 12:57:45,067 [MainThread  ] [INFO ]  Processing text.48.txt.\n",
      "[2019-10-08 12:57:45,067 INFO] Processing text.48.txt.\n",
      "2019-10-08 12:57:45,069 [MainThread  ] [INFO ]  Processing text.49.txt.\n",
      "[2019-10-08 12:57:45,069 INFO] Processing text.49.txt.\n",
      "2019-10-08 12:57:45,072 [MainThread  ] [INFO ]  Processing text.5.txt.\n",
      "[2019-10-08 12:57:45,072 INFO] Processing text.5.txt.\n",
      "2019-10-08 12:57:45,074 [MainThread  ] [INFO ]  Processing text.50.txt.\n",
      "[2019-10-08 12:57:45,074 INFO] Processing text.50.txt.\n",
      "2019-10-08 12:57:45,077 [MainThread  ] [INFO ]  Processing text.51.txt.\n",
      "[2019-10-08 12:57:45,077 INFO] Processing text.51.txt.\n",
      "2019-10-08 12:57:45,080 [MainThread  ] [INFO ]  Processing text.52.txt.\n",
      "[2019-10-08 12:57:45,080 INFO] Processing text.52.txt.\n",
      "2019-10-08 12:57:45,083 [MainThread  ] [INFO ]  Processing text.53.txt.\n",
      "[2019-10-08 12:57:45,083 INFO] Processing text.53.txt.\n",
      "2019-10-08 12:57:45,085 [MainThread  ] [INFO ]  Processing text.54.txt.\n",
      "[2019-10-08 12:57:45,085 INFO] Processing text.54.txt.\n",
      "2019-10-08 12:57:45,087 [MainThread  ] [INFO ]  Processing text.55.txt.\n",
      "[2019-10-08 12:57:45,087 INFO] Processing text.55.txt.\n",
      "2019-10-08 12:57:45,090 [MainThread  ] [INFO ]  Processing text.56.txt.\n",
      "[2019-10-08 12:57:45,090 INFO] Processing text.56.txt.\n",
      "2019-10-08 12:57:45,093 [MainThread  ] [INFO ]  Processing text.57.txt.\n",
      "[2019-10-08 12:57:45,093 INFO] Processing text.57.txt.\n",
      "2019-10-08 12:57:45,095 [MainThread  ] [INFO ]  Processing text.58.txt.\n",
      "[2019-10-08 12:57:45,095 INFO] Processing text.58.txt.\n",
      "2019-10-08 12:57:45,098 [MainThread  ] [INFO ]  Processing text.59.txt.\n",
      "[2019-10-08 12:57:45,098 INFO] Processing text.59.txt.\n",
      "2019-10-08 12:57:45,100 [MainThread  ] [INFO ]  Processing text.6.txt.\n",
      "[2019-10-08 12:57:45,100 INFO] Processing text.6.txt.\n",
      "2019-10-08 12:57:45,103 [MainThread  ] [INFO ]  Processing text.60.txt.\n",
      "[2019-10-08 12:57:45,103 INFO] Processing text.60.txt.\n",
      "2019-10-08 12:57:45,105 [MainThread  ] [INFO ]  Processing text.61.txt.\n",
      "[2019-10-08 12:57:45,105 INFO] Processing text.61.txt.\n",
      "2019-10-08 12:57:45,108 [MainThread  ] [INFO ]  Processing text.62.txt.\n",
      "[2019-10-08 12:57:45,108 INFO] Processing text.62.txt.\n",
      "2019-10-08 12:57:45,109 [MainThread  ] [INFO ]  Processing text.63.txt.\n",
      "[2019-10-08 12:57:45,109 INFO] Processing text.63.txt.\n",
      "2019-10-08 12:57:45,112 [MainThread  ] [INFO ]  Processing text.64.txt.\n",
      "[2019-10-08 12:57:45,112 INFO] Processing text.64.txt.\n",
      "2019-10-08 12:57:45,115 [MainThread  ] [INFO ]  Processing text.65.txt.\n",
      "[2019-10-08 12:57:45,115 INFO] Processing text.65.txt.\n",
      "2019-10-08 12:57:45,117 [MainThread  ] [INFO ]  Processing text.66.txt.\n",
      "[2019-10-08 12:57:45,117 INFO] Processing text.66.txt.\n",
      "2019-10-08 12:57:45,119 [MainThread  ] [INFO ]  Processing text.67.txt.\n",
      "[2019-10-08 12:57:45,119 INFO] Processing text.67.txt.\n",
      "2019-10-08 12:57:45,121 [MainThread  ] [INFO ]  Processing text.68.txt.\n",
      "[2019-10-08 12:57:45,121 INFO] Processing text.68.txt.\n",
      "2019-10-08 12:57:45,124 [MainThread  ] [INFO ]  Processing text.69.txt.\n",
      "[2019-10-08 12:57:45,124 INFO] Processing text.69.txt.\n",
      "2019-10-08 12:57:45,127 [MainThread  ] [INFO ]  Processing text.7.txt.\n",
      "[2019-10-08 12:57:45,127 INFO] Processing text.7.txt.\n",
      "2019-10-08 12:57:45,129 [MainThread  ] [INFO ]  Processing text.70.txt.\n",
      "[2019-10-08 12:57:45,129 INFO] Processing text.70.txt.\n",
      "2019-10-08 12:57:45,132 [MainThread  ] [INFO ]  Processing text.71.txt.\n",
      "[2019-10-08 12:57:45,132 INFO] Processing text.71.txt.\n",
      "2019-10-08 12:57:45,134 [MainThread  ] [INFO ]  Processing text.72.txt.\n",
      "[2019-10-08 12:57:45,134 INFO] Processing text.72.txt.\n",
      "2019-10-08 12:57:45,136 [MainThread  ] [INFO ]  Processing text.73.txt.\n",
      "[2019-10-08 12:57:45,136 INFO] Processing text.73.txt.\n",
      "2019-10-08 12:57:45,139 [MainThread  ] [INFO ]  Processing text.74.txt.\n",
      "[2019-10-08 12:57:45,139 INFO] Processing text.74.txt.\n",
      "2019-10-08 12:57:45,141 [MainThread  ] [INFO ]  Processing text.75.txt.\n",
      "[2019-10-08 12:57:45,141 INFO] Processing text.75.txt.\n",
      "2019-10-08 12:57:45,144 [MainThread  ] [INFO ]  Processing text.76.txt.\n",
      "[2019-10-08 12:57:45,144 INFO] Processing text.76.txt.\n",
      "2019-10-08 12:57:45,147 [MainThread  ] [INFO ]  Processing text.77.txt.\n",
      "[2019-10-08 12:57:45,147 INFO] Processing text.77.txt.\n",
      "2019-10-08 12:57:45,149 [MainThread  ] [INFO ]  Processing text.78.txt.\n",
      "[2019-10-08 12:57:45,149 INFO] Processing text.78.txt.\n",
      "2019-10-08 12:57:45,152 [MainThread  ] [INFO ]  Processing text.79.txt.\n",
      "[2019-10-08 12:57:45,152 INFO] Processing text.79.txt.\n",
      "2019-10-08 12:57:45,154 [MainThread  ] [INFO ]  Processing text.8.txt.\n",
      "[2019-10-08 12:57:45,154 INFO] Processing text.8.txt.\n",
      "2019-10-08 12:57:45,157 [MainThread  ] [INFO ]  Processing text.80.txt.\n",
      "[2019-10-08 12:57:45,157 INFO] Processing text.80.txt.\n",
      "2019-10-08 12:57:45,160 [MainThread  ] [INFO ]  Processing text.81.txt.\n",
      "[2019-10-08 12:57:45,160 INFO] Processing text.81.txt.\n",
      "2019-10-08 12:57:45,162 [MainThread  ] [INFO ]  Processing text.82.txt.\n",
      "[2019-10-08 12:57:45,162 INFO] Processing text.82.txt.\n",
      "2019-10-08 12:57:45,165 [MainThread  ] [INFO ]  Processing text.83.txt.\n",
      "[2019-10-08 12:57:45,165 INFO] Processing text.83.txt.\n",
      "2019-10-08 12:57:45,168 [MainThread  ] [INFO ]  Processing text.84.txt.\n",
      "[2019-10-08 12:57:45,168 INFO] Processing text.84.txt.\n",
      "2019-10-08 12:57:45,171 [MainThread  ] [INFO ]  Processing text.85.txt.\n",
      "[2019-10-08 12:57:45,171 INFO] Processing text.85.txt.\n",
      "2019-10-08 12:57:45,174 [MainThread  ] [INFO ]  Processing text.86.txt.\n",
      "[2019-10-08 12:57:45,174 INFO] Processing text.86.txt.\n",
      "2019-10-08 12:57:45,177 [MainThread  ] [INFO ]  Processing text.87.txt.\n",
      "[2019-10-08 12:57:45,177 INFO] Processing text.87.txt.\n",
      "2019-10-08 12:57:45,181 [MainThread  ] [INFO ]  Processing text.88.txt.\n",
      "[2019-10-08 12:57:45,181 INFO] Processing text.88.txt.\n",
      "2019-10-08 12:57:45,183 [MainThread  ] [INFO ]  Processing text.89.txt.\n",
      "[2019-10-08 12:57:45,183 INFO] Processing text.89.txt.\n",
      "2019-10-08 12:57:45,186 [MainThread  ] [INFO ]  Processing text.9.txt.\n",
      "[2019-10-08 12:57:45,186 INFO] Processing text.9.txt.\n",
      "2019-10-08 12:57:45,189 [MainThread  ] [INFO ]  Processing text.90.txt.\n",
      "[2019-10-08 12:57:45,189 INFO] Processing text.90.txt.\n",
      "2019-10-08 12:57:45,192 [MainThread  ] [INFO ]  Processing text.91.txt.\n",
      "[2019-10-08 12:57:45,192 INFO] Processing text.91.txt.\n",
      "2019-10-08 12:57:45,195 [MainThread  ] [INFO ]  Processing text.92.txt.\n",
      "[2019-10-08 12:57:45,195 INFO] Processing text.92.txt.\n",
      "2019-10-08 12:57:45,197 [MainThread  ] [INFO ]  Processing text.93.txt.\n",
      "[2019-10-08 12:57:45,197 INFO] Processing text.93.txt.\n",
      "2019-10-08 12:57:45,199 [MainThread  ] [INFO ]  Processing text.94.txt.\n",
      "[2019-10-08 12:57:45,199 INFO] Processing text.94.txt.\n",
      "2019-10-08 12:57:45,202 [MainThread  ] [INFO ]  Processing text.95.txt.\n",
      "[2019-10-08 12:57:45,202 INFO] Processing text.95.txt.\n",
      "2019-10-08 12:57:45,204 [MainThread  ] [INFO ]  Processing text.96.txt.\n",
      "[2019-10-08 12:57:45,204 INFO] Processing text.96.txt.\n",
      "2019-10-08 12:57:45,206 [MainThread  ] [INFO ]  Processing text.97.txt.\n",
      "[2019-10-08 12:57:45,206 INFO] Processing text.97.txt.\n",
      "2019-10-08 12:57:45,209 [MainThread  ] [INFO ]  Processing text.98.txt.\n",
      "[2019-10-08 12:57:45,209 INFO] Processing text.98.txt.\n",
      "2019-10-08 12:57:45,212 [MainThread  ] [INFO ]  Processing text.99.txt.\n",
      "[2019-10-08 12:57:45,212 INFO] Processing text.99.txt.\n",
      "2019-10-08 12:57:45,214 [MainThread  ] [INFO ]  Saved processed files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\system.\n",
      "[2019-10-08 12:57:45,214 INFO] Saved processed files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\system.\n",
      "2019-10-08 12:57:45,216 [MainThread  ] [INFO ]  Processing files in ../logs/right1/cand.\n",
      "[2019-10-08 12:57:45,216 INFO] Processing files in ../logs/right1/cand.\n",
      "2019-10-08 12:57:45,217 [MainThread  ] [INFO ]  Processing abs_bert_aeslc.4000.candidate.\n",
      "[2019-10-08 12:57:45,217 INFO] Processing abs_bert_aeslc.4000.candidate.\n",
      "2019-10-08 12:57:45,220 [MainThread  ] [INFO ]  Processing text.C.0.txt.\n",
      "[2019-10-08 12:57:45,220 INFO] Processing text.C.0.txt.\n",
      "2019-10-08 12:57:45,222 [MainThread  ] [INFO ]  Processing text.C.1.txt.\n",
      "[2019-10-08 12:57:45,222 INFO] Processing text.C.1.txt.\n",
      "2019-10-08 12:57:45,225 [MainThread  ] [INFO ]  Processing text.C.10.txt.\n",
      "[2019-10-08 12:57:45,225 INFO] Processing text.C.10.txt.\n",
      "2019-10-08 12:57:45,228 [MainThread  ] [INFO ]  Processing text.C.100.txt.\n",
      "[2019-10-08 12:57:45,228 INFO] Processing text.C.100.txt.\n",
      "2019-10-08 12:57:45,230 [MainThread  ] [INFO ]  Processing text.C.101.txt.\n",
      "[2019-10-08 12:57:45,230 INFO] Processing text.C.101.txt.\n",
      "2019-10-08 12:57:45,233 [MainThread  ] [INFO ]  Processing text.C.102.txt.\n",
      "[2019-10-08 12:57:45,233 INFO] Processing text.C.102.txt.\n",
      "2019-10-08 12:57:45,236 [MainThread  ] [INFO ]  Processing text.C.103.txt.\n",
      "[2019-10-08 12:57:45,236 INFO] Processing text.C.103.txt.\n",
      "2019-10-08 12:57:45,239 [MainThread  ] [INFO ]  Processing text.C.104.txt.\n",
      "[2019-10-08 12:57:45,239 INFO] Processing text.C.104.txt.\n",
      "2019-10-08 12:57:45,242 [MainThread  ] [INFO ]  Processing text.C.105.txt.\n",
      "[2019-10-08 12:57:45,242 INFO] Processing text.C.105.txt.\n",
      "2019-10-08 12:57:45,245 [MainThread  ] [INFO ]  Processing text.C.106.txt.\n",
      "[2019-10-08 12:57:45,245 INFO] Processing text.C.106.txt.\n",
      "2019-10-08 12:57:45,249 [MainThread  ] [INFO ]  Processing text.C.107.txt.\n",
      "[2019-10-08 12:57:45,249 INFO] Processing text.C.107.txt.\n",
      "2019-10-08 12:57:45,253 [MainThread  ] [INFO ]  Processing text.C.108.txt.\n",
      "[2019-10-08 12:57:45,253 INFO] Processing text.C.108.txt.\n",
      "2019-10-08 12:57:45,257 [MainThread  ] [INFO ]  Processing text.C.109.txt.\n",
      "[2019-10-08 12:57:45,257 INFO] Processing text.C.109.txt.\n",
      "2019-10-08 12:57:45,260 [MainThread  ] [INFO ]  Processing text.C.11.txt.\n",
      "[2019-10-08 12:57:45,260 INFO] Processing text.C.11.txt.\n",
      "2019-10-08 12:57:45,262 [MainThread  ] [INFO ]  Processing text.C.110.txt.\n",
      "[2019-10-08 12:57:45,262 INFO] Processing text.C.110.txt.\n",
      "2019-10-08 12:57:45,264 [MainThread  ] [INFO ]  Processing text.C.111.txt.\n",
      "[2019-10-08 12:57:45,264 INFO] Processing text.C.111.txt.\n",
      "2019-10-08 12:57:45,267 [MainThread  ] [INFO ]  Processing text.C.112.txt.\n",
      "[2019-10-08 12:57:45,267 INFO] Processing text.C.112.txt.\n",
      "2019-10-08 12:57:45,269 [MainThread  ] [INFO ]  Processing text.C.113.txt.\n",
      "[2019-10-08 12:57:45,269 INFO] Processing text.C.113.txt.\n",
      "2019-10-08 12:57:45,272 [MainThread  ] [INFO ]  Processing text.C.114.txt.\n",
      "[2019-10-08 12:57:45,272 INFO] Processing text.C.114.txt.\n",
      "2019-10-08 12:57:45,275 [MainThread  ] [INFO ]  Processing text.C.115.txt.\n",
      "[2019-10-08 12:57:45,275 INFO] Processing text.C.115.txt.\n",
      "2019-10-08 12:57:45,278 [MainThread  ] [INFO ]  Processing text.C.116.txt.\n",
      "[2019-10-08 12:57:45,278 INFO] Processing text.C.116.txt.\n",
      "2019-10-08 12:57:45,280 [MainThread  ] [INFO ]  Processing text.C.117.txt.\n",
      "[2019-10-08 12:57:45,280 INFO] Processing text.C.117.txt.\n",
      "2019-10-08 12:57:45,283 [MainThread  ] [INFO ]  Processing text.C.118.txt.\n",
      "[2019-10-08 12:57:45,283 INFO] Processing text.C.118.txt.\n",
      "2019-10-08 12:57:45,285 [MainThread  ] [INFO ]  Processing text.C.119.txt.\n",
      "[2019-10-08 12:57:45,285 INFO] Processing text.C.119.txt.\n",
      "2019-10-08 12:57:45,287 [MainThread  ] [INFO ]  Processing text.C.12.txt.\n",
      "[2019-10-08 12:57:45,287 INFO] Processing text.C.12.txt.\n",
      "2019-10-08 12:57:45,290 [MainThread  ] [INFO ]  Processing text.C.120.txt.\n",
      "[2019-10-08 12:57:45,290 INFO] Processing text.C.120.txt.\n",
      "2019-10-08 12:57:45,293 [MainThread  ] [INFO ]  Processing text.C.121.txt.\n",
      "[2019-10-08 12:57:45,293 INFO] Processing text.C.121.txt.\n",
      "2019-10-08 12:57:45,296 [MainThread  ] [INFO ]  Processing text.C.122.txt.\n",
      "[2019-10-08 12:57:45,296 INFO] Processing text.C.122.txt.\n",
      "2019-10-08 12:57:45,298 [MainThread  ] [INFO ]  Processing text.C.123.txt.\n",
      "[2019-10-08 12:57:45,298 INFO] Processing text.C.123.txt.\n",
      "2019-10-08 12:57:45,301 [MainThread  ] [INFO ]  Processing text.C.124.txt.\n",
      "[2019-10-08 12:57:45,301 INFO] Processing text.C.124.txt.\n",
      "2019-10-08 12:57:45,303 [MainThread  ] [INFO ]  Processing text.C.125.txt.\n",
      "[2019-10-08 12:57:45,303 INFO] Processing text.C.125.txt.\n",
      "2019-10-08 12:57:45,305 [MainThread  ] [INFO ]  Processing text.C.126.txt.\n",
      "[2019-10-08 12:57:45,305 INFO] Processing text.C.126.txt.\n",
      "2019-10-08 12:57:45,308 [MainThread  ] [INFO ]  Processing text.C.127.txt.\n",
      "[2019-10-08 12:57:45,308 INFO] Processing text.C.127.txt.\n",
      "2019-10-08 12:57:45,311 [MainThread  ] [INFO ]  Processing text.C.128.txt.\n",
      "[2019-10-08 12:57:45,311 INFO] Processing text.C.128.txt.\n",
      "2019-10-08 12:57:45,313 [MainThread  ] [INFO ]  Processing text.C.129.txt.\n",
      "[2019-10-08 12:57:45,313 INFO] Processing text.C.129.txt.\n",
      "2019-10-08 12:57:45,316 [MainThread  ] [INFO ]  Processing text.C.13.txt.\n",
      "[2019-10-08 12:57:45,316 INFO] Processing text.C.13.txt.\n",
      "2019-10-08 12:57:45,319 [MainThread  ] [INFO ]  Processing text.C.130.txt.\n",
      "[2019-10-08 12:57:45,319 INFO] Processing text.C.130.txt.\n",
      "2019-10-08 12:57:45,322 [MainThread  ] [INFO ]  Processing text.C.131.txt.\n",
      "[2019-10-08 12:57:45,322 INFO] Processing text.C.131.txt.\n",
      "2019-10-08 12:57:45,324 [MainThread  ] [INFO ]  Processing text.C.132.txt.\n",
      "[2019-10-08 12:57:45,324 INFO] Processing text.C.132.txt.\n",
      "2019-10-08 12:57:45,327 [MainThread  ] [INFO ]  Processing text.C.133.txt.\n",
      "[2019-10-08 12:57:45,327 INFO] Processing text.C.133.txt.\n",
      "2019-10-08 12:57:45,330 [MainThread  ] [INFO ]  Processing text.C.134.txt.\n",
      "[2019-10-08 12:57:45,330 INFO] Processing text.C.134.txt.\n",
      "2019-10-08 12:57:45,333 [MainThread  ] [INFO ]  Processing text.C.135.txt.\n",
      "[2019-10-08 12:57:45,333 INFO] Processing text.C.135.txt.\n",
      "2019-10-08 12:57:45,335 [MainThread  ] [INFO ]  Processing text.C.136.txt.\n",
      "[2019-10-08 12:57:45,335 INFO] Processing text.C.136.txt.\n",
      "2019-10-08 12:57:45,338 [MainThread  ] [INFO ]  Processing text.C.137.txt.\n",
      "[2019-10-08 12:57:45,338 INFO] Processing text.C.137.txt.\n",
      "2019-10-08 12:57:45,341 [MainThread  ] [INFO ]  Processing text.C.138.txt.\n",
      "[2019-10-08 12:57:45,341 INFO] Processing text.C.138.txt.\n",
      "2019-10-08 12:57:45,343 [MainThread  ] [INFO ]  Processing text.C.139.txt.\n",
      "[2019-10-08 12:57:45,343 INFO] Processing text.C.139.txt.\n",
      "2019-10-08 12:57:45,346 [MainThread  ] [INFO ]  Processing text.C.14.txt.\n",
      "[2019-10-08 12:57:45,346 INFO] Processing text.C.14.txt.\n",
      "2019-10-08 12:57:45,348 [MainThread  ] [INFO ]  Processing text.C.140.txt.\n",
      "[2019-10-08 12:57:45,348 INFO] Processing text.C.140.txt.\n",
      "2019-10-08 12:57:45,350 [MainThread  ] [INFO ]  Processing text.C.141.txt.\n",
      "[2019-10-08 12:57:45,350 INFO] Processing text.C.141.txt.\n",
      "2019-10-08 12:57:45,353 [MainThread  ] [INFO ]  Processing text.C.142.txt.\n",
      "[2019-10-08 12:57:45,353 INFO] Processing text.C.142.txt.\n",
      "2019-10-08 12:57:45,355 [MainThread  ] [INFO ]  Processing text.C.143.txt.\n",
      "[2019-10-08 12:57:45,355 INFO] Processing text.C.143.txt.\n",
      "2019-10-08 12:57:45,357 [MainThread  ] [INFO ]  Processing text.C.144.txt.\n",
      "[2019-10-08 12:57:45,357 INFO] Processing text.C.144.txt.\n",
      "2019-10-08 12:57:45,359 [MainThread  ] [INFO ]  Processing text.C.145.txt.\n",
      "[2019-10-08 12:57:45,359 INFO] Processing text.C.145.txt.\n",
      "2019-10-08 12:57:45,361 [MainThread  ] [INFO ]  Processing text.C.146.txt.\n",
      "[2019-10-08 12:57:45,361 INFO] Processing text.C.146.txt.\n",
      "2019-10-08 12:57:45,363 [MainThread  ] [INFO ]  Processing text.C.147.txt.\n",
      "[2019-10-08 12:57:45,363 INFO] Processing text.C.147.txt.\n",
      "2019-10-08 12:57:45,366 [MainThread  ] [INFO ]  Processing text.C.148.txt.\n",
      "[2019-10-08 12:57:45,366 INFO] Processing text.C.148.txt.\n",
      "2019-10-08 12:57:45,368 [MainThread  ] [INFO ]  Processing text.C.149.txt.\n",
      "[2019-10-08 12:57:45,368 INFO] Processing text.C.149.txt.\n",
      "2019-10-08 12:57:45,371 [MainThread  ] [INFO ]  Processing text.C.15.txt.\n",
      "[2019-10-08 12:57:45,371 INFO] Processing text.C.15.txt.\n",
      "2019-10-08 12:57:45,373 [MainThread  ] [INFO ]  Processing text.C.150.txt.\n",
      "[2019-10-08 12:57:45,373 INFO] Processing text.C.150.txt.\n",
      "2019-10-08 12:57:45,375 [MainThread  ] [INFO ]  Processing text.C.151.txt.\n",
      "[2019-10-08 12:57:45,375 INFO] Processing text.C.151.txt.\n",
      "2019-10-08 12:57:45,378 [MainThread  ] [INFO ]  Processing text.C.152.txt.\n",
      "[2019-10-08 12:57:45,378 INFO] Processing text.C.152.txt.\n",
      "2019-10-08 12:57:45,380 [MainThread  ] [INFO ]  Processing text.C.153.txt.\n",
      "[2019-10-08 12:57:45,380 INFO] Processing text.C.153.txt.\n",
      "2019-10-08 12:57:45,382 [MainThread  ] [INFO ]  Processing text.C.154.txt.\n",
      "[2019-10-08 12:57:45,382 INFO] Processing text.C.154.txt.\n",
      "2019-10-08 12:57:45,385 [MainThread  ] [INFO ]  Processing text.C.155.txt.\n",
      "[2019-10-08 12:57:45,385 INFO] Processing text.C.155.txt.\n",
      "2019-10-08 12:57:45,387 [MainThread  ] [INFO ]  Processing text.C.156.txt.\n",
      "[2019-10-08 12:57:45,387 INFO] Processing text.C.156.txt.\n",
      "2019-10-08 12:57:45,390 [MainThread  ] [INFO ]  Processing text.C.157.txt.\n",
      "[2019-10-08 12:57:45,390 INFO] Processing text.C.157.txt.\n",
      "2019-10-08 12:57:45,392 [MainThread  ] [INFO ]  Processing text.C.158.txt.\n",
      "[2019-10-08 12:57:45,392 INFO] Processing text.C.158.txt.\n",
      "2019-10-08 12:57:45,395 [MainThread  ] [INFO ]  Processing text.C.159.txt.\n",
      "[2019-10-08 12:57:45,395 INFO] Processing text.C.159.txt.\n",
      "2019-10-08 12:57:45,398 [MainThread  ] [INFO ]  Processing text.C.16.txt.\n",
      "[2019-10-08 12:57:45,398 INFO] Processing text.C.16.txt.\n",
      "2019-10-08 12:57:45,400 [MainThread  ] [INFO ]  Processing text.C.160.txt.\n",
      "[2019-10-08 12:57:45,400 INFO] Processing text.C.160.txt.\n",
      "2019-10-08 12:57:45,403 [MainThread  ] [INFO ]  Processing text.C.161.txt.\n",
      "[2019-10-08 12:57:45,403 INFO] Processing text.C.161.txt.\n",
      "2019-10-08 12:57:45,405 [MainThread  ] [INFO ]  Processing text.C.162.txt.\n",
      "[2019-10-08 12:57:45,405 INFO] Processing text.C.162.txt.\n",
      "2019-10-08 12:57:45,407 [MainThread  ] [INFO ]  Processing text.C.163.txt.\n",
      "[2019-10-08 12:57:45,407 INFO] Processing text.C.163.txt.\n",
      "2019-10-08 12:57:45,410 [MainThread  ] [INFO ]  Processing text.C.164.txt.\n",
      "[2019-10-08 12:57:45,410 INFO] Processing text.C.164.txt.\n",
      "2019-10-08 12:57:45,412 [MainThread  ] [INFO ]  Processing text.C.165.txt.\n",
      "[2019-10-08 12:57:45,412 INFO] Processing text.C.165.txt.\n",
      "2019-10-08 12:57:45,414 [MainThread  ] [INFO ]  Processing text.C.166.txt.\n",
      "[2019-10-08 12:57:45,414 INFO] Processing text.C.166.txt.\n",
      "2019-10-08 12:57:45,416 [MainThread  ] [INFO ]  Processing text.C.167.txt.\n",
      "[2019-10-08 12:57:45,416 INFO] Processing text.C.167.txt.\n",
      "2019-10-08 12:57:45,419 [MainThread  ] [INFO ]  Processing text.C.168.txt.\n",
      "[2019-10-08 12:57:45,419 INFO] Processing text.C.168.txt.\n",
      "2019-10-08 12:57:45,421 [MainThread  ] [INFO ]  Processing text.C.169.txt.\n",
      "[2019-10-08 12:57:45,421 INFO] Processing text.C.169.txt.\n",
      "2019-10-08 12:57:45,423 [MainThread  ] [INFO ]  Processing text.C.17.txt.\n",
      "[2019-10-08 12:57:45,423 INFO] Processing text.C.17.txt.\n",
      "2019-10-08 12:57:45,425 [MainThread  ] [INFO ]  Processing text.C.170.txt.\n",
      "[2019-10-08 12:57:45,425 INFO] Processing text.C.170.txt.\n",
      "2019-10-08 12:57:45,428 [MainThread  ] [INFO ]  Processing text.C.171.txt.\n",
      "[2019-10-08 12:57:45,428 INFO] Processing text.C.171.txt.\n",
      "2019-10-08 12:57:45,431 [MainThread  ] [INFO ]  Processing text.C.172.txt.\n",
      "[2019-10-08 12:57:45,431 INFO] Processing text.C.172.txt.\n",
      "2019-10-08 12:57:45,433 [MainThread  ] [INFO ]  Processing text.C.173.txt.\n",
      "[2019-10-08 12:57:45,433 INFO] Processing text.C.173.txt.\n",
      "2019-10-08 12:57:45,435 [MainThread  ] [INFO ]  Processing text.C.18.txt.\n",
      "[2019-10-08 12:57:45,435 INFO] Processing text.C.18.txt.\n",
      "2019-10-08 12:57:45,437 [MainThread  ] [INFO ]  Processing text.C.19.txt.\n",
      "[2019-10-08 12:57:45,437 INFO] Processing text.C.19.txt.\n",
      "2019-10-08 12:57:45,440 [MainThread  ] [INFO ]  Processing text.C.2.txt.\n",
      "[2019-10-08 12:57:45,440 INFO] Processing text.C.2.txt.\n",
      "2019-10-08 12:57:45,442 [MainThread  ] [INFO ]  Processing text.C.20.txt.\n",
      "[2019-10-08 12:57:45,442 INFO] Processing text.C.20.txt.\n",
      "2019-10-08 12:57:45,445 [MainThread  ] [INFO ]  Processing text.C.21.txt.\n",
      "[2019-10-08 12:57:45,445 INFO] Processing text.C.21.txt.\n",
      "2019-10-08 12:57:45,447 [MainThread  ] [INFO ]  Processing text.C.22.txt.\n",
      "[2019-10-08 12:57:45,447 INFO] Processing text.C.22.txt.\n",
      "2019-10-08 12:57:45,450 [MainThread  ] [INFO ]  Processing text.C.23.txt.\n",
      "[2019-10-08 12:57:45,450 INFO] Processing text.C.23.txt.\n",
      "2019-10-08 12:57:45,452 [MainThread  ] [INFO ]  Processing text.C.24.txt.\n",
      "[2019-10-08 12:57:45,452 INFO] Processing text.C.24.txt.\n",
      "2019-10-08 12:57:45,455 [MainThread  ] [INFO ]  Processing text.C.25.txt.\n",
      "[2019-10-08 12:57:45,455 INFO] Processing text.C.25.txt.\n",
      "2019-10-08 12:57:45,458 [MainThread  ] [INFO ]  Processing text.C.26.txt.\n",
      "[2019-10-08 12:57:45,458 INFO] Processing text.C.26.txt.\n",
      "2019-10-08 12:57:45,461 [MainThread  ] [INFO ]  Processing text.C.27.txt.\n",
      "[2019-10-08 12:57:45,461 INFO] Processing text.C.27.txt.\n",
      "2019-10-08 12:57:45,464 [MainThread  ] [INFO ]  Processing text.C.28.txt.\n",
      "[2019-10-08 12:57:45,464 INFO] Processing text.C.28.txt.\n",
      "2019-10-08 12:57:45,466 [MainThread  ] [INFO ]  Processing text.C.29.txt.\n",
      "[2019-10-08 12:57:45,466 INFO] Processing text.C.29.txt.\n",
      "2019-10-08 12:57:45,468 [MainThread  ] [INFO ]  Processing text.C.3.txt.\n",
      "[2019-10-08 12:57:45,468 INFO] Processing text.C.3.txt.\n",
      "2019-10-08 12:57:45,470 [MainThread  ] [INFO ]  Processing text.C.30.txt.\n",
      "[2019-10-08 12:57:45,470 INFO] Processing text.C.30.txt.\n",
      "2019-10-08 12:57:45,473 [MainThread  ] [INFO ]  Processing text.C.31.txt.\n",
      "[2019-10-08 12:57:45,473 INFO] Processing text.C.31.txt.\n",
      "2019-10-08 12:57:45,475 [MainThread  ] [INFO ]  Processing text.C.32.txt.\n",
      "[2019-10-08 12:57:45,475 INFO] Processing text.C.32.txt.\n",
      "2019-10-08 12:57:45,477 [MainThread  ] [INFO ]  Processing text.C.33.txt.\n",
      "[2019-10-08 12:57:45,477 INFO] Processing text.C.33.txt.\n",
      "2019-10-08 12:57:45,480 [MainThread  ] [INFO ]  Processing text.C.34.txt.\n",
      "[2019-10-08 12:57:45,480 INFO] Processing text.C.34.txt.\n",
      "2019-10-08 12:57:45,482 [MainThread  ] [INFO ]  Processing text.C.35.txt.\n",
      "[2019-10-08 12:57:45,482 INFO] Processing text.C.35.txt.\n",
      "2019-10-08 12:57:45,483 [MainThread  ] [INFO ]  Processing text.C.36.txt.\n",
      "[2019-10-08 12:57:45,483 INFO] Processing text.C.36.txt.\n",
      "2019-10-08 12:57:45,486 [MainThread  ] [INFO ]  Processing text.C.37.txt.\n",
      "[2019-10-08 12:57:45,486 INFO] Processing text.C.37.txt.\n",
      "2019-10-08 12:57:45,488 [MainThread  ] [INFO ]  Processing text.C.38.txt.\n",
      "[2019-10-08 12:57:45,488 INFO] Processing text.C.38.txt.\n",
      "2019-10-08 12:57:45,490 [MainThread  ] [INFO ]  Processing text.C.39.txt.\n",
      "[2019-10-08 12:57:45,490 INFO] Processing text.C.39.txt.\n",
      "2019-10-08 12:57:45,492 [MainThread  ] [INFO ]  Processing text.C.4.txt.\n",
      "[2019-10-08 12:57:45,492 INFO] Processing text.C.4.txt.\n",
      "2019-10-08 12:57:45,495 [MainThread  ] [INFO ]  Processing text.C.40.txt.\n",
      "[2019-10-08 12:57:45,495 INFO] Processing text.C.40.txt.\n",
      "2019-10-08 12:57:45,498 [MainThread  ] [INFO ]  Processing text.C.41.txt.\n",
      "[2019-10-08 12:57:45,498 INFO] Processing text.C.41.txt.\n",
      "2019-10-08 12:57:45,500 [MainThread  ] [INFO ]  Processing text.C.42.txt.\n",
      "[2019-10-08 12:57:45,500 INFO] Processing text.C.42.txt.\n",
      "2019-10-08 12:57:45,502 [MainThread  ] [INFO ]  Processing text.C.43.txt.\n",
      "[2019-10-08 12:57:45,502 INFO] Processing text.C.43.txt.\n",
      "2019-10-08 12:57:45,505 [MainThread  ] [INFO ]  Processing text.C.44.txt.\n",
      "[2019-10-08 12:57:45,505 INFO] Processing text.C.44.txt.\n",
      "2019-10-08 12:57:45,507 [MainThread  ] [INFO ]  Processing text.C.45.txt.\n",
      "[2019-10-08 12:57:45,507 INFO] Processing text.C.45.txt.\n",
      "2019-10-08 12:57:45,510 [MainThread  ] [INFO ]  Processing text.C.46.txt.\n",
      "[2019-10-08 12:57:45,510 INFO] Processing text.C.46.txt.\n",
      "2019-10-08 12:57:45,513 [MainThread  ] [INFO ]  Processing text.C.47.txt.\n",
      "[2019-10-08 12:57:45,513 INFO] Processing text.C.47.txt.\n",
      "2019-10-08 12:57:45,517 [MainThread  ] [INFO ]  Processing text.C.48.txt.\n",
      "[2019-10-08 12:57:45,517 INFO] Processing text.C.48.txt.\n",
      "2019-10-08 12:57:45,520 [MainThread  ] [INFO ]  Processing text.C.49.txt.\n",
      "[2019-10-08 12:57:45,520 INFO] Processing text.C.49.txt.\n",
      "2019-10-08 12:57:45,523 [MainThread  ] [INFO ]  Processing text.C.5.txt.\n",
      "[2019-10-08 12:57:45,523 INFO] Processing text.C.5.txt.\n",
      "2019-10-08 12:57:45,525 [MainThread  ] [INFO ]  Processing text.C.50.txt.\n",
      "[2019-10-08 12:57:45,525 INFO] Processing text.C.50.txt.\n",
      "2019-10-08 12:57:45,529 [MainThread  ] [INFO ]  Processing text.C.51.txt.\n",
      "[2019-10-08 12:57:45,529 INFO] Processing text.C.51.txt.\n",
      "2019-10-08 12:57:45,531 [MainThread  ] [INFO ]  Processing text.C.52.txt.\n",
      "[2019-10-08 12:57:45,531 INFO] Processing text.C.52.txt.\n",
      "2019-10-08 12:57:45,534 [MainThread  ] [INFO ]  Processing text.C.53.txt.\n",
      "[2019-10-08 12:57:45,534 INFO] Processing text.C.53.txt.\n",
      "2019-10-08 12:57:45,536 [MainThread  ] [INFO ]  Processing text.C.54.txt.\n",
      "[2019-10-08 12:57:45,536 INFO] Processing text.C.54.txt.\n",
      "2019-10-08 12:57:45,539 [MainThread  ] [INFO ]  Processing text.C.55.txt.\n",
      "[2019-10-08 12:57:45,539 INFO] Processing text.C.55.txt.\n",
      "2019-10-08 12:57:45,541 [MainThread  ] [INFO ]  Processing text.C.56.txt.\n",
      "[2019-10-08 12:57:45,541 INFO] Processing text.C.56.txt.\n",
      "2019-10-08 12:57:45,544 [MainThread  ] [INFO ]  Processing text.C.57.txt.\n",
      "[2019-10-08 12:57:45,544 INFO] Processing text.C.57.txt.\n",
      "2019-10-08 12:57:45,547 [MainThread  ] [INFO ]  Processing text.C.58.txt.\n",
      "[2019-10-08 12:57:45,547 INFO] Processing text.C.58.txt.\n",
      "2019-10-08 12:57:45,550 [MainThread  ] [INFO ]  Processing text.C.59.txt.\n",
      "[2019-10-08 12:57:45,550 INFO] Processing text.C.59.txt.\n",
      "2019-10-08 12:57:45,552 [MainThread  ] [INFO ]  Processing text.C.6.txt.\n",
      "[2019-10-08 12:57:45,552 INFO] Processing text.C.6.txt.\n",
      "2019-10-08 12:57:45,555 [MainThread  ] [INFO ]  Processing text.C.60.txt.\n",
      "[2019-10-08 12:57:45,555 INFO] Processing text.C.60.txt.\n",
      "2019-10-08 12:57:45,557 [MainThread  ] [INFO ]  Processing text.C.61.txt.\n",
      "[2019-10-08 12:57:45,557 INFO] Processing text.C.61.txt.\n",
      "2019-10-08 12:57:45,560 [MainThread  ] [INFO ]  Processing text.C.62.txt.\n",
      "[2019-10-08 12:57:45,560 INFO] Processing text.C.62.txt.\n",
      "2019-10-08 12:57:45,563 [MainThread  ] [INFO ]  Processing text.C.63.txt.\n",
      "[2019-10-08 12:57:45,563 INFO] Processing text.C.63.txt.\n",
      "2019-10-08 12:57:45,565 [MainThread  ] [INFO ]  Processing text.C.64.txt.\n",
      "[2019-10-08 12:57:45,565 INFO] Processing text.C.64.txt.\n",
      "2019-10-08 12:57:45,569 [MainThread  ] [INFO ]  Processing text.C.65.txt.\n",
      "[2019-10-08 12:57:45,569 INFO] Processing text.C.65.txt.\n",
      "2019-10-08 12:57:45,571 [MainThread  ] [INFO ]  Processing text.C.66.txt.\n",
      "[2019-10-08 12:57:45,571 INFO] Processing text.C.66.txt.\n",
      "2019-10-08 12:57:45,573 [MainThread  ] [INFO ]  Processing text.C.67.txt.\n",
      "[2019-10-08 12:57:45,573 INFO] Processing text.C.67.txt.\n",
      "2019-10-08 12:57:45,575 [MainThread  ] [INFO ]  Processing text.C.68.txt.\n",
      "[2019-10-08 12:57:45,575 INFO] Processing text.C.68.txt.\n",
      "2019-10-08 12:57:45,578 [MainThread  ] [INFO ]  Processing text.C.69.txt.\n",
      "[2019-10-08 12:57:45,578 INFO] Processing text.C.69.txt.\n",
      "2019-10-08 12:57:45,581 [MainThread  ] [INFO ]  Processing text.C.7.txt.\n",
      "[2019-10-08 12:57:45,581 INFO] Processing text.C.7.txt.\n",
      "2019-10-08 12:57:45,584 [MainThread  ] [INFO ]  Processing text.C.70.txt.\n",
      "[2019-10-08 12:57:45,584 INFO] Processing text.C.70.txt.\n",
      "2019-10-08 12:57:45,588 [MainThread  ] [INFO ]  Processing text.C.71.txt.\n",
      "[2019-10-08 12:57:45,588 INFO] Processing text.C.71.txt.\n",
      "2019-10-08 12:57:45,590 [MainThread  ] [INFO ]  Processing text.C.72.txt.\n",
      "[2019-10-08 12:57:45,590 INFO] Processing text.C.72.txt.\n",
      "2019-10-08 12:57:45,593 [MainThread  ] [INFO ]  Processing text.C.73.txt.\n",
      "[2019-10-08 12:57:45,593 INFO] Processing text.C.73.txt.\n",
      "2019-10-08 12:57:45,597 [MainThread  ] [INFO ]  Processing text.C.74.txt.\n",
      "[2019-10-08 12:57:45,597 INFO] Processing text.C.74.txt.\n",
      "2019-10-08 12:57:45,600 [MainThread  ] [INFO ]  Processing text.C.75.txt.\n",
      "[2019-10-08 12:57:45,600 INFO] Processing text.C.75.txt.\n",
      "2019-10-08 12:57:45,602 [MainThread  ] [INFO ]  Processing text.C.76.txt.\n",
      "[2019-10-08 12:57:45,602 INFO] Processing text.C.76.txt.\n",
      "2019-10-08 12:57:45,605 [MainThread  ] [INFO ]  Processing text.C.77.txt.\n",
      "[2019-10-08 12:57:45,605 INFO] Processing text.C.77.txt.\n",
      "2019-10-08 12:57:45,608 [MainThread  ] [INFO ]  Processing text.C.78.txt.\n",
      "[2019-10-08 12:57:45,608 INFO] Processing text.C.78.txt.\n",
      "2019-10-08 12:57:45,612 [MainThread  ] [INFO ]  Processing text.C.79.txt.\n",
      "[2019-10-08 12:57:45,612 INFO] Processing text.C.79.txt.\n",
      "2019-10-08 12:57:45,615 [MainThread  ] [INFO ]  Processing text.C.8.txt.\n",
      "[2019-10-08 12:57:45,615 INFO] Processing text.C.8.txt.\n",
      "2019-10-08 12:57:45,618 [MainThread  ] [INFO ]  Processing text.C.80.txt.\n",
      "[2019-10-08 12:57:45,618 INFO] Processing text.C.80.txt.\n",
      "2019-10-08 12:57:45,620 [MainThread  ] [INFO ]  Processing text.C.81.txt.\n",
      "[2019-10-08 12:57:45,620 INFO] Processing text.C.81.txt.\n",
      "2019-10-08 12:57:45,623 [MainThread  ] [INFO ]  Processing text.C.82.txt.\n",
      "[2019-10-08 12:57:45,623 INFO] Processing text.C.82.txt.\n",
      "2019-10-08 12:57:45,625 [MainThread  ] [INFO ]  Processing text.C.83.txt.\n",
      "[2019-10-08 12:57:45,625 INFO] Processing text.C.83.txt.\n",
      "2019-10-08 12:57:45,628 [MainThread  ] [INFO ]  Processing text.C.84.txt.\n",
      "[2019-10-08 12:57:45,628 INFO] Processing text.C.84.txt.\n",
      "2019-10-08 12:57:45,631 [MainThread  ] [INFO ]  Processing text.C.85.txt.\n",
      "[2019-10-08 12:57:45,631 INFO] Processing text.C.85.txt.\n",
      "2019-10-08 12:57:45,634 [MainThread  ] [INFO ]  Processing text.C.86.txt.\n",
      "[2019-10-08 12:57:45,634 INFO] Processing text.C.86.txt.\n",
      "2019-10-08 12:57:45,637 [MainThread  ] [INFO ]  Processing text.C.87.txt.\n",
      "[2019-10-08 12:57:45,637 INFO] Processing text.C.87.txt.\n",
      "2019-10-08 12:57:45,639 [MainThread  ] [INFO ]  Processing text.C.88.txt.\n",
      "[2019-10-08 12:57:45,639 INFO] Processing text.C.88.txt.\n",
      "2019-10-08 12:57:45,642 [MainThread  ] [INFO ]  Processing text.C.89.txt.\n",
      "[2019-10-08 12:57:45,642 INFO] Processing text.C.89.txt.\n",
      "2019-10-08 12:57:45,645 [MainThread  ] [INFO ]  Processing text.C.9.txt.\n",
      "[2019-10-08 12:57:45,645 INFO] Processing text.C.9.txt.\n",
      "2019-10-08 12:57:45,648 [MainThread  ] [INFO ]  Processing text.C.90.txt.\n",
      "[2019-10-08 12:57:45,648 INFO] Processing text.C.90.txt.\n",
      "2019-10-08 12:57:45,650 [MainThread  ] [INFO ]  Processing text.C.91.txt.\n",
      "[2019-10-08 12:57:45,650 INFO] Processing text.C.91.txt.\n",
      "2019-10-08 12:57:45,653 [MainThread  ] [INFO ]  Processing text.C.92.txt.\n",
      "[2019-10-08 12:57:45,653 INFO] Processing text.C.92.txt.\n",
      "2019-10-08 12:57:45,656 [MainThread  ] [INFO ]  Processing text.C.93.txt.\n",
      "[2019-10-08 12:57:45,656 INFO] Processing text.C.93.txt.\n",
      "2019-10-08 12:57:45,659 [MainThread  ] [INFO ]  Processing text.C.94.txt.\n",
      "[2019-10-08 12:57:45,659 INFO] Processing text.C.94.txt.\n",
      "2019-10-08 12:57:45,662 [MainThread  ] [INFO ]  Processing text.C.95.txt.\n",
      "[2019-10-08 12:57:45,662 INFO] Processing text.C.95.txt.\n",
      "2019-10-08 12:57:45,666 [MainThread  ] [INFO ]  Processing text.C.96.txt.\n",
      "[2019-10-08 12:57:45,666 INFO] Processing text.C.96.txt.\n",
      "2019-10-08 12:57:45,669 [MainThread  ] [INFO ]  Processing text.C.97.txt.\n",
      "[2019-10-08 12:57:45,669 INFO] Processing text.C.97.txt.\n",
      "2019-10-08 12:57:45,671 [MainThread  ] [INFO ]  Processing text.C.98.txt.\n",
      "[2019-10-08 12:57:45,671 INFO] Processing text.C.98.txt.\n",
      "2019-10-08 12:57:45,675 [MainThread  ] [INFO ]  Processing text.C.99.txt.\n",
      "[2019-10-08 12:57:45,675 INFO] Processing text.C.99.txt.\n",
      "2019-10-08 12:57:45,678 [MainThread  ] [INFO ]  Saved processed files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\model.\n",
      "[2019-10-08 12:57:45,678 INFO] Saved processed files to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmp1_v83rpx\\model.\n",
      "2019-10-08 12:57:46,451 [MainThread  ] [INFO ]  Written ROUGE configuration to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmpbcrxj9os\\rouge_conf.xml\n",
      "[2019-10-08 12:57:46,451 INFO] Written ROUGE configuration to C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmpbcrxj9os\\rouge_conf.xml\n",
      "2019-10-08 12:57:46,453 [MainThread  ] [INFO ]  Running ROUGE with command perl  D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\ROUGE-1.5.5.pl -e D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmpbcrxj9os\\rouge_conf.xml\n",
      "[2019-10-08 12:57:46,453 INFO] Running ROUGE with command perl  D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\ROUGE-1.5.5.pl -e D:\\study\\pyrouge-master\\tools\\ROUGE-1.5.5\\data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m C:\\Users\\Lilikili\\AppData\\Local\\Temp\\tmpbcrxj9os\\rouge_conf.xml\n"
     ]
    }
   ],
   "source": [
    "from pyrouge import Rouge155\n",
    "r = Rouge155()\n",
    "\n",
    "r.system_dir = '../logs/right1/gold'\n",
    "r.model_dir = '../logs/right1/cand'\n",
    "r.system_filename_pattern = 'text.(\\d+).txt'\n",
    "r.model_filename_pattern = 'text.[A-Z].#ID#.txt'\n",
    "\n",
    "output = r.convert_and_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rouge-1 Average_R: 0.01475 \n",
    "Rouge-1 Average_P: 0.27450 \n",
    "Rouge-1 Average_F: 0.02780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---------------------------------------------\\r\\n1 Rouge-1 Average_R: 0.01475 (95%-Conf.Int. 0.01153 - 0.01864)\\r\\n1 Rouge-1 Average_P: 0.27450 (95%-Conf.Int. 0.21552 - 0.33908)\\r\\n1 Rouge-1 Average_F: 0.02780 (95%-Conf.Int. 0.02182 - 0.03509)\\r\\n---------------------------------------------\\r\\n1 Rouge-2 Average_R: 0.00201 (95%-Conf.Int. 0.00090 - 0.00331)\\r\\n1 Rouge-2 Average_P: 0.05878 (95%-Conf.Int. 0.02874 - 0.09770)\\r\\n1 Rouge-2 Average_F: 0.00388 (95%-Conf.Int. 0.00175 - 0.00640)\\r\\n---------------------------------------------\\r\\n1 Rouge-3 Average_R: 0.00000 (95%-Conf.Int. 0.00000 - 0.00000)\\r\\n1 Rouge-3 Average_P: 0.00000 (95%-Conf.Int. 0.00000 - 0.00000)\\r\\n1 Rouge-3 Average_F: 0.00000 (95%-Conf.Int. 0.00000 - 0.00000)\\r\\n---------------------------------------------\\r\\n1 Rouge-4 Average_R: 0.00000 (95%-Conf.Int. 0.00000 - 0.00000)\\r\\n1 Rouge-4 Average_P: 0.00000 (95%-Conf.Int. 0.00000 - 0.00000)\\r\\n1 Rouge-4 Average_F: 0.00000 (95%-Conf.Int. 0.00000 - 0.00000)\\r\\n---------------------------------------------\\r\\n1 Rouge-L Average_R: 0.01475 (95%-Conf.Int. 0.01153 - 0.01864)\\r\\n1 Rouge-L Average_P: 0.27450 (95%-Conf.Int. 0.21552 - 0.33908)\\r\\n1 Rouge-L Average_F: 0.02780 (95%-Conf.Int. 0.02182 - 0.03509)\\r\\n---------------------------------------------\\r\\n1 Rouge-W-1.2 Average_R: 0.00757 (95%-Conf.Int. 0.00591 - 0.00963)\\r\\n1 Rouge-W-1.2 Average_P: 0.27006 (95%-Conf.Int. 0.21400 - 0.33182)\\r\\n1 Rouge-W-1.2 Average_F: 0.01465 (95%-Conf.Int. 0.01147 - 0.01861)\\r\\n---------------------------------------------\\r\\n1 Rouge-S* Average_R: 0.00016 (95%-Conf.Int. 0.00008 - 0.00026)\\r\\n1 Rouge-S* Average_P: 0.07572 (95%-Conf.Int. 0.04023 - 0.11494)\\r\\n1 Rouge-S* Average_F: 0.00032 (95%-Conf.Int. 0.00017 - 0.00051)\\r\\n---------------------------------------------\\r\\n1 Rouge-Su* Average_R: 0.00038 (95%-Conf.Int. 0.00021 - 0.00057)\\r\\n1 Rouge-Su* Average_P: 0.09318 (95%-Conf.Int. 0.05460 - 0.13793)\\r\\n1 Rouge-Su* Average_F: 0.00075 (95%-Conf.Int. 0.00042 - 0.00113)\\r\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
